hashMap为什么头插入链表? 设计者觉得后插入被查找的可能性更大。
初始长度16，自动或手动初始化，都是2的幂。
hash值取摸简单，但是效率很低，所以采用位运算。因为2的n次方-1，都是11111..所以都是依赖于输入的哈希值的尾巴，只要哈希函数均匀，就可以均匀。
HashTable在新的代码已经不推荐使用，ConcurrentHashMap更好.HashMap允许一个null为key
HashMap java8增加了红黑树的结构，桶查找算法复杂度O(n)降低到了O(logn) resize的优化。
hashMap线程不安全，put可能造成线程丢失被覆盖，get的时候遇到resize会造成线程不安全, 因为重新resize之后，可能形成循环链表.
HashMap 8之前都是头插入因为作者觉得后写入的值更先访问 wtf，8开始改用尾插法，因为这样能保持扩容后的相对链表的指向方向，避免循环链表
jdk7 使用segment,默认16个，jdk8摈弃了segment。而是node数组，链表超过8会转换为红黑树。
synchronizedMap
fail-safe(拷贝对象遍历) 与  fail-fast区别
hashtable的key不允许为null，因为早期觉得元素都要实现equals和hashCode方法，null肯定没有，但是hashMap会放到一个特殊的位置
ConcurrentHashMap put的时候会CAS尝试写入，失败就自旋，数量大会转换红黑树, 
红黑树的自平衡性比较好，让它高度很低
hashmap负载因子为什么是0.75

treeSet的内部就是treeMap实现，使用的红黑树来实现的.要求key能排序.
冒泡排序就是两两连续比较
选择排序，遍历一遍找到最小，第二遍找第二小...以此类推
插入排序，拿第一个放到开头，第n个元素依次来找已经排序好的数组进行选择位置插入.
希尔排序，是分成若干个数组进行插入排序。

- zk
zookeeper,znode的数据存储信息,zk适合读多写少，每个节点最大不能1M.
zk集群，更新leader，再更新follower，读取可以任何机器.
一致性采用了ZAB(zk automic broadcast)协议.类似于paxos和raft
zab定义的节点三个状态：looking,  following, leading, observing
zxid包含最大事务编号和epoch。
zab : discover->sync->broadcast
顺序一致性：https://segmentfault.com/a/1190000022248118
zk 并不适合做注册中心，会有不一致性的短暂时间负载不够均衡，而且不同机房分区后不能调同机房的机器不合理。
leader挂了，整个集群对外的服务停止开始选举。
3.4 后保留fastLeaderElection，分两个情况，启动集群已经有leader直接同步即可， 没leader就开始zxid和sid的投票信息进行交换，第一轮是投自己然后进行对比，如果收到比自己的大，那第二轮就拿大的继续投票，直到选出leader，由looking变更为following状态,投票的报文里还有队列或则第几轮和状态的标志，避免消息紊乱。 为了避免重复连接tcp，都是sid大的连接sid小的，建立连接就会判断这个sid如果比自己大直接断开 。


- redis
redis集群方案有redis cluster类似于节点redirect， redis sharding客户端进行路由、proxy代理。几种分片和扩容方式对比。
redis按存储模式可以分为内存和硬盘，硬盘模式是在内存提供索引，内存模式是不依赖硬盘IO
redis压缩的二进制文件， save和bgsave命令，分别阻塞和不阻塞客户进程.可以通过配置来控制频率刷新写入RDB文件.
10w qps
redis快，内存，数据结构，单线程CPU不是瓶颈 ，多路复用IO，非阻塞。
Sorted set 实现是使用的 skiplist表是分层链表，加快查询速度，不用遍历了，写入和删除都是随机层，不用动太多指针
redis String的 SDS一系列对空间的优化
rehash渐进式，在重新hash的过程操作两个表，这样避免一次性耗费大量时间处理.
zset 有序链表 使用skipList 
RDB和AOF的备份方式,AOF又分三种模式，主要是频率的控制 ,RDB更多适合大文件和恢复要更快， AOF适合数据的完整性.
redis 事务ACID的A原子性并不能总是保证，因为其没回滚特性，作者认为客户端的代码没问题就不应该报错。
redis 主从复制保持高可用，slave先sync拉取RDB文件，这个时候主master写到缓冲区不写RDB，RDB拉取完了加载到内存，master再同步缓冲区的命令给slave，后续建立连接进行
redis 主从同步，2.8版本之前都是全量同步，但是只是 redis失去连接或则停止运行恢复没必要全部重新拉取，所以slave会发送psync发送id标志和offset，master确认是之前连过就从offset开始同步，否则还是拉全量。
集群数据分布方式：节点取摸，一致性哈希(可以虚拟节点增加均匀，把一个真实节点拆成多个节点均匀分布到环上)，哈希槽(redis-cluster)。
集群的一些坑：批量操作，事务，限制为一个节点
哨兵是新引入一个进程高可用方案，哨兵也是集群，就是监控master是否存活，自动切换当前slave为master, 独立进程，也会互相监控.如果主机挂了，哨兵主管认为其master下线，等待其他哨兵也认为它下线然后进行投票选举新的master
sentinel也是一个集群，会连接所有master和slave redis节点，如果某台机器下线了，先主观下线，再根据其他sentinel节点的信息汇总，超过阀值就会判定为客观下线，进行投票选择新的。其中很多阀值可以进行配置 。
sentinel 会对master进行cmd连接通信，与其他sentinal节点用pub/sub进程通信。 
redis的淘汰策略，就是在有限内存内，如果继续写入，根据策略进行淘汰kv，否则超出了会与磁盘进行频繁交互影响性能，allkeys-lru算法淘汰，volatile-lru:设置过期时间的淘汰，随机淘汰等策略.
lru是根据最近使用的频率来看，用的很少就淘汰
4.0增加LFU，就是访问的频率
主要是从是否设置过过期时间的 key去淘汰，可以根据最先过期，或则通过访问次数和频率.还有比较暴力的随机淘汰策略。
redis的SDS直接存放了字符串的长度，避免了C语言的遍历计算长度和扩容开销，因为拼接一次之后会有个free长度去缓冲，避免每次拼接都扩容带来开销。缩容不会马上删除。 这就是两个解决方案：空间预分配和惰性空间释放.
redis的事务不能保证隔离型
redis的watch就是在事务开启之前监听某个key变化，乐观锁机制，如果变化了执行就会返回失败


- mq 

-- rocketMQ
rocketMQ是开源版本，metaQ notify 和aliware MQ都是以rocketMQ为内核开发出来的产品，metaQ主要是pull,解决顺序消息和海量堆积问题， Notify是推模型，解决事务消息， Aliware MQ则是商业化的版本.
rocketMQ : nameServer, broker, producer, consumer
nameServer和zk的功能差不多，但是更轻量
producer只是向master发送消息，但是consumer可以从master和slave订阅消息 
rocket参考的kafka设计的,都采用了零拷贝技术,在可靠性和事务性上做了优化，性能略降低。
吞吐量在十万级别，kafka达到百万级别
kafka 消息还没到broker就返回成功，rocketMQ会保证发送到再返回，因此kafka可能会丢数据 （刚好broker宕机）
因为只需要一个比较轻量高可用的协调集群，所以没引入zk
零拷贝，就是避免CPU把数据从磁盘读取到内核空间缓存和socket缓存的两次复制，用一些技术让出了CPU资源。
消息重复一般都是让消费者控制的，可以redis判断唯一id控制
rocketMQ在4.5之前master-slave是没有故障自动转移，需要人工介入，4.5之后支持故障切换，因为引入了DLedger记录commitLog，可以用raft选举出新的leader
nameServer检查broker存活是有延迟的，因此如何规避broker的问题，一般就是重试和--

-- kafka
高可用的核心就是冗余副本（partition）
leader是partition的纬度
创建topic可以设置复制因子，决定副本的个数
一个topics有多个partition分布在不同的机器上，每个partition有多个副本在不同的机器
kafka的写入写入性能取决于ISR集合中最慢的broker接受消息的性能, 运维可以最好识别出来最慢的broker干掉
这个 ISR怎样才算跟得上，这个可以通过参数配置，可以是落后的消息数量也可以是follower主要fetch（也是配置）的延迟时间
replica.lag.time.max.ms就是落后的数量，但是这样可能在峰值的时候频繁删除ISR和恢复，所以kafka是优化了落后数量判断并且下个fetch时间内没追上，才会移除ISR
每个partition（leader patition）都有个一个ISR(In-Sync Replicas)，维护着跟自己partition同步的副本
leader有两个指针，指向committed和logEndOffset，分别指向已经提交的和还没同步完成的.(https://zhuanlan.zhihu.com/p/56440807)
acks参数在生产者里，有三个选项0,1,all.  0-客户端发送出去就不管了，性能最高但是可靠性最差，1-leader保存还没同步就返回成功，all-必须要同步ISR里的机器成功再返回，性能最差
acks参数至少要有副本才有意义
kafka消费者记录offset
Kafka HW:high waterbark,最小的ISR机器的水位 leo:logEndOffset   hw和leo都是最后一条的下一条
顺序性，parition内是顺序写入的，所以消费也是有序，如果要topic有序，那就partitio的个数设置为1，当然这样就没高可用了
kafka consumer如果超过了partition个数，那多余的机器不会消费到topics,所以这里没法线性扩展.
kafka 的高性能，partition的并行处理能力, 磁盘的顺序写能力，把partition分为多个segment，segment对应一个文件，按文件删除.
生产和消费差不多，Page cache避免写入磁盘的等待，直接消费，但是可能宕机丢失，不过可以用partition冗余解决这个问题。
零拷贝 kafka节点投递给消费者的时候避免了内核态到用户态的复制过程 https://www.jianshu.com/p/835ec2d4c170
批量发送消息，和数据压缩，broker发送搞得时候再解压，整个过程磁盘的数据写入写出都降低了


- 分布式事务
XA 资源协调
TCC try-commit-cancel, 要求允许空回滚和幂等,主要解决异步网络通信失败问题，主要的核心就是重试。
soga : 一阶段提交，要么全成功，要么全失败，也是补偿，一阶段，不会对资源长期加锁，吞吐量相对较高
MQ消息: 发送先把消息投递到消息队列，但是此时消息队列的该消息只是prepare状态，不会给消费者消费，直到等生产者执行成功通知mq说该消息成功，这里有个问题，可能网路不好，一直没通知mq,这个时候mq有个定时任务轮训prepare状态的消息来查接口得到状态，如果消费成功则然后通知下游去消费，不断的重试，最终得到一致。
本地消息表:记录表不断的重试，不支持回滚
ACID : 柔性事务一般会放弃强一致和隔离性

- mysql
mysql innoDB如果没定义primary key，就选择第一个唯一键的索引作为pk。
为什么要用自增主键好，因为顺序插入，数据紧凑不需要挪动数据。非自增的话会为了保证B+树的顺序，所以可能频繁移动造成碎片，不紧凑性能降低。
索引，有序，二分查找快
B+是有序的，叶子节点有指针指向。
哈希是无序的，单key查找不需要遍历树，速度极快，但是不擅长范围查询和排序，联合作引左匹配也不支持。
B+查询的时候引擎会分析查询自动触发自适应查询构建哈希索引。客户端不可控制，隐式的。 
表分区是把单表的物理存储拆分成多个，逻辑上还是一个，分表是按某个业务字段进行分表。分区可以存储更多数据，需要并行查询汇总，删数据更容易。
MVCC 提高了读的并发度
limit 1找到一条就停止，可以是一个优化点
MRR(multi range read) 就是读取了索引一起然后排序再去磁盘上拿数据，避免频繁IO磁盘非顺序读。因为mysql都是一页一页的查询，顺序读后一页的缓存不会丢失导致非顺序读重复读某页，会找到需要数据结束后再失效缓存。
B+主要是避免了B树的遍历排序问题
innoDB 存在缓冲管理，索引和数据全部缓存起来，加快查询速度
innoDB相比MySAM最大特点就是支持事务，损失效率换来的
explain的index是索引全部扫描，ref是更快的查找
联合索引的的b+树都是根据第一个索引字段去构建的 
mysql执行:连接器->查询缓存->分析器->优化器，查询缓存是缓存整张表.除非是静态表缓存价值不大。
意向锁是表锁，与其互斥的也是普通表锁，一个数据要对某行加锁，就要先获取表的意向锁再获取表的行锁。意向锁增加了并发度，表和行锁共存。
乐观锁、悲观锁，共享锁和排他锁都是悲观锁。
mysql大量update的时候，就算走的索引也会升级为表锁，因为行锁的开销大。不走索引的话也是直接表锁.
间隙锁，给不存在的数据区间加锁，避免幻读(因此在写多的场景，尽量避免范围加锁, 和大范围加锁)。如果使用条件记录给不存在的记录加锁，也会间隙锁。
update和delete 索引区分度不高的场景，引发锁表。
innoDB有监控线程主动检测死锁并通知，回滚代价最小的那个事务。
show OPEN TABLES where In_use > 0查看是否锁表.
死锁文章https://juejin.im/post/5b82e0196fb9a019f47d1823
内存三大模块：缓冲池、重做缓存池(Redo Log Buffer)和额外内存池. 
innoDB为了抵抗高并发，抵消CPU与IO的速度差异，引入了缓冲池，读就是先读缓存池读不到再读磁盘然后写入到缓存池，跟缓存一样一样的，写的话也是修改缓存池再去刷盘，降低IO交互。当然如果全表扫描的话会导致缓存池被占满，这个采用了LRU算法淘汰避免。
MySQL都是日志先行，写数据前都会Redo Log,定期CheckPoint将RedoLog刷入磁盘。
写入都是批量写入缓存量达到某个值再刷盘。但是这里如果宕机就没办法RedoLog了，所以要用两次写入，不仅写入内存缓冲池，还要在磁盘共享空间也写个副本，避免丢失。
访问热点的页进行hash自适应，类似于JIT。
重做日志缓冲，写RedoLog然后更改缓冲区，更改的页叫脏页，根据Checkpoint将脏页刷到磁盘。
MySQL日志：错误日志、二进制文件、查询日志、慢查询日志。InnoDB日志：Redo Log和Undo Log


- jvm
jvm stack frame存放局部变量，操作栈，动态连接，方法出口等信息，与线程生命周期一致,局部变量表再编译期确定大小，不会改变
方法区(也叫非堆)存放类信息，常量，静态变量，jit后的代码的代码等数据，这块垃圾回收主要是常量池的回收也对类的卸载，回收效果一般不太好，
hotspot当成永久代管理方法区，1.8移除，改成了一个叫元空间的一个东西(也就是说从堆内存移动到了物理内存)，与之前的永久代的区别就是这个元空间是受物理内存的限制，不会再抛出OME了.
java可以利用直接内存，虽然不再jvm规范内，但是可以缓冲区nio去操作，这样避免了jvm内的复制过程，有时候可以明显提升性能。
Java内存模型是一个规范，主要规定了线程件的可见性和共享变量的同步，也就是线程私有变量和主内存的一个交互逻辑规范。
堆，方法区，执行引擎和本地接口是线程共享的，栈和程序计数器是线程私有的。
多线程环境下栈创建过多也可以OME，如果栈太深了也可以StackOutflowError
JMM只保证基本的读取和直接(int a = 1)赋值是原子操作
原子性，可见性，有序性
指令重排序单个线程不会影响，但是多个线程
volatile和synchronize都可以保证原子性，volatile是改了之后直接刷新到主存，synchronize是在释放锁之前把所有的改动写入到主存
jvm内存结构，内存模型，对象模型 区分
jvm就是各个部分的一个规范，内存模型就是多线程之间的共享，对象模型就是具体格式
现在都是分代垃圾收集算法，新生代Minior GC非常频繁，回收快。老年代Major GC,速度慢，频率低。
优先年轻代，大对象和长期存活对象进入老年代，为了计算“长期”，会给每个对象一个年龄计数器。默认15(可以配置)次移动还存在就晋升老年代。
判断对象是否死亡，引用计数法效率高，简单，但是循环引用比较麻烦。主要还是靠可达性分析。
引用类型：强引用 内存不够就抛出OME。  软引用 平时不回收，当内存空间不足就回收。  弱引用  回收线程扫描弱引用就回收（优先级比较低，所以不一定会回收），虚引用。
软引用比其他两个更弱的引用更有价值，主要避免OME
扫描到了被标记而已，还可以执行finalize方法，执行完了再检查一次是否可达，如果不可达才可以真的回收。
常量池也是进行引用查看，没有引用就直接回收了。
对于类的标记，实例都回收、该ClassLoader被回收，Class引用没引用，就可以(不是必然)回收。
算法：标记-清除（效率，碎片），复制算法（解决前一个问题，年轻代），标记-整理（老年代），分代收集

垃圾收集器：
Serial单线程效率高但是STW体验不好.
ParNew就是Serial的多线程版本（并发执行，效率更高，但是也会STW），
Parallel Scavenge与ParNew类似，但更关注吞吐量。
Serial old为Serial的老年代版本。
Parallel Old为Parallel Scavenge的老年代版本。
CMS为最短暂停顿时间为目标的GC(第一款并发收集，与用户线程同时执行,初始标题，并发标记，重新标记，并发清除四个阶段)优点并发收集，低停顿，但是对CPU资源敏感，无法处理浮动垃圾，会产生空间碎片。
G1 高性能多核大内存的机器，最大限度降低STW, 特点：并行并发，分代收集，空间整合，可预测停顿。

FullGC就是针对各个代要分配的空间不够的情况全面回收。
Minor GC 为新生代（eden和两个survivor）的回收。Eden区满的时候触发。存活的移动到survivor，from -> to (空的)
如果Minor GC回收发现剩下eden和survivor加起来大于survivor就会提前移动到老年代，这样多了之后老年代FullGC都不够溢出就内存泄漏了。
JVM避免Minor GC扫描全堆，因为新生代可能引用老年代对象，要识别GC roots，就扫描到老年代了，可以采用卡表的技术，把老年代按空间大小分成多个卡片，如果有新生代引用的，就把卡表标记为脏卡，到时候寻找GC roots就可以只扫描脏卡了，不需要进行全堆扫描。

jvm的类加载和连接与初始化都是在运行期间完成的，这种策略会增加编程的灵活性，但是会损失一点点性能。
类的生命周期：加载、验证、准备、解析、初始化、使用、卸载。其中解析可以在初始化之后进行，因为要实现动态绑定。
触发加载的唯一五种方式。1. 遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果累没有进行初始化，则要先触发初始化；
    2. 使用java.lang.reflect包中的方法对类进行反射调用的时候；
    3. 初始化类时，若发现其父类还没有初始化，则先触发父类的初始化；
    4. 虚拟机启动的时候，虚拟机会先初始化用户指定的包含main()方法的那个类
    5. 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。

数组 new Object[]不会触发初始化。final 阶段的常量会在编译期就放常量池了，不会触发初始化。
类的初始化是类的各个成员赋初始值的过程。
准备是给static变量分配内存设置初始值(类型初始值)的阶段。final的话会池实话为定义值。
解析就是把符号引用转换成直接引用。
初始化是执行类构造<clinit>(注意区分实例构造器)static部分方法的过程。程序员定义的static代码。
类构造器先执行父类再执行子类，可以没有类构造器


LinkedBlockingQueue无界队列可以指定，有写和读两个锁（竞争不那么激烈），复杂度更高扩容内存开销大些，内部链表存储。
ArrayBlockingQueue需要指定长度，读写都是一个锁，竞争激烈一下，内存开销小一些。
DelayQueue可以自定义过期时间的获取优先级的队列。
https://juejin.im/post/5c3ac10351882524bb0b337f
底层都是一个AQS同步器，通过CAS的原子操作更新state去更新获取锁的次数，重入锁就增加1.实现了一个队列进行唤醒。
公平锁是让先挂起的先获取锁，但是非公平锁会唤起所有挂起的线程然后抢，可能存在后挂起的先抢到。
sleep 会在中断后清除中断标记
synchronized本质是要加锁排队的阻塞队列，volatile是没有锁的，因此开销会少，使用的是内存屏障。

CAS中的自旋锁一般要设定次数，否则会带来较大的CPU开销.


spring的循环依赖解决方案，1. 重新设计依赖关系 2.懒加载 3.setter加载
Spring的构造一个对象是先是实例化依赖的对象再设置属性值。实例化了对象就会放到缓存里面，不会再继续递归去实例化。三级缓存不同成品的bean对象.


nio就是避免了bio的一个连接保持一个服务器的内存消耗。采用不停轮询的方式，具体实现java使用了客户端的buffer 和一个双工的channel和服务端的selector去操作的。selector不停的轮询多个channel把数据发送给客户端的buffer
steam是单向，channel是双向的
同步就是要拿结果，无论是等待或则不断的轮询都是同步。异步就是不用等待，通知我就好了。
阻塞就是数据就绪后，采用的方式是等待还是立即返回。

TCP协议的滑动窗口避免阻塞发生。不用每个包都等待。可以等待一批再等待，这样提高网络吞吐量。
Dubbo的SPI机制，就是有个ExtensionLoader可以根据情况加载接口的不同实现。
CopyOnWriteArrayList的思想就是对于并发容器读写分离，但是写入加锁也会阻塞读，这样不好，所以采取复制一个对象写入完成再把原先引用指向来解决，这个可能存在脏读的风险。


算法：
分治法、贪心法、回溯、动态规划。
分治法把大问题化小，每个问题都是独立的问题。
动态规划，是不断的分解问题，把结果进行合并，与分治法的区别就是非独立的问题，建立在之前的结果之上。 

问题：
循环依赖问题
AQS
redis的优化
引用类型
项目亮点和难题
hashMap死锁
StringBuffer 相比StringBuilder的优势
每日算法 
零拷贝技术
消息队列的高可用，顺序性
kafka的消费者于partition是固定的么
kafka的磁盘处理
分布式事务超时
B+结构
表分区具体怎么操作
日活，量级
treeMap与treeSet区别
各个排序算法
线程池参数
redis事务协调
意向锁
流量控制
mybatis事务
https原理
nio bio io
2pc和3pc
mapreduce介绍下

内存屏障

zk的顺序一致性
redis 集群的proxy高可用和高性能问题
java对象创建过程
对象访问定位有几种
双亲委派
dump文件
嵌入式tomcat
RequestMapping和GetMapping区别

对Mike Cohn的测试金字塔了解多少?
Mock或Stub有什么区别?
什么是OAuth ?
什么是CopyOnWrite 
redis怎么实现分布式锁
redis高并发和高可用
redis数据类型和应用
Dubbo SPI机制
redis和zk分布锁对比
redis集群如何做分片
事务的隔离级别如何控制 

自我介绍要谈项目和角色


腾讯面试针对性准备：
https的解决什么问题
设计一个UDP
tcp的一些滑动机制
协程和线程的区别
GO的一些机制
KMP

threadLocal内存泄漏

----- 
调研：
加强部分：
链表，树的遍历, 
操作系统与网络, GO相关
熟练掌握HTTP/HTTPS协议，理解TCP/IP协议，并具备linux下的网络服务编程经验。
面经

三次握手：
最开始服务器为LISTEN
发起请求，包含随机生成的seq序列号，syn字段设置为1，表示请求连接。 (syn=1, seq=x) 客户端SENT
由服务端回复客户端包含随机生成seq号，syn设置为1， 产生ack=客户端的syn+1  (syn=1, ack=x+1,seq=y) 服务端RCVD
客户端收到请求后，再次回复(syn=1, ack=y+1, seq=x+1) 客户端与服务端ESTABLISHED

三次握手是基于效率和可靠性去考虑的，如果就两次没有最后一次，那客户端可能不需要连接了服务端还干等浪费资源.

四次挥手：
都是established状态
客户端发起断开，(fin=1, seq=x),  客户端变为fin_wait1, 服务点变为close_wait 
服务端响应：(fin=1, ack=x+1, seq=y)  客户端fin_wait2
服务端处理完成响应: (fin=1,ack=x+1,seq=z)
客户端相应:(fin=1, ack=z+1, seq=h) 客户端等待2MSL，服务端LAST_ACK然后关闭

为什么还要等待2msl，因为避免客户端的ack丢包，导致服务器重复请求断开客户端不能识别。

tcp中几个函数：
tcp网络变成的connect就是一个阻塞函数，就是发起三次握手的建立连接.listen是被动链接函数，告诉内核监听，其中一个backlog作用就是设置队列长度.accept就是从established队列中取已经完成的连接 当队列没有完成连接会阻塞。

关于tcp的图文：https://blog.51cto.com/jinlong/2065461

加密：
对称加密，私钥是同一个，性能比较高，但是密钥的管理比较困难。
非对称加密，私钥和公钥成对出现，但是速度比较慢。
https就是http的ssl/tls版本，tls为ssl3.0后的版本。tls与ssl3.0加密算法不同，宏观来看效果一样。
https结合两种方式，非对称加密传递密钥，对称加密传输数据。
https连接会通过两次请求响应连接，第一次是请求服务器，获得证书签名的公钥A。然后客户端验证过了再生成一个随机密钥B，用服务端的公钥A，服务器用私钥C解密获得公钥，然后建立连接开始传输数据。

tcp与udp的区别：
tcp有流量控制、保证传输顺序、面向字节流
udp没流量控制、不保证顺序、面向数据包

UDP可靠性传输：udp+数据包序列号、确认和重传机制、CRC校验完整性.

协程和线程一样共享的堆，私有的栈，协程由程序员在协程里显示调度。协程是单线程内的调度切换，cpu调度的单位是线程。

fork(). vfork(). clone(). exec()都是linux创建新进程，linux内核没有线程结构，只有轻量级进程。
fork创建子进程独立父进程空间
vfork与父线程共享空间，会阻塞父进程直到子进程执行完。
clone为fork的升级版，更灵活的创建，可以创建父进程的兄弟进程。

linux查看网络状态：ifconfig  thtool ip

tcp滑动窗口就是为了解决大数据量的分批发送问题，就像一个窗口移动，所以叫滑动窗口协议，窗口是在tcp三次握手之后协定，不是固定的，会随机调整，数据分四个部分，已发送并且收到回复，已发送还没收到回复，允许发送但还没发送，不允许发送，窗口可以看成[已发送还没通知，可发送还没发送].滑动窗口的意义保证可靠性和传输效率，稳定性。

tcp包头结构：固定20字节(32位*5行)，包含端口，序号，确认号，窗口等.

http客户端状态码，1xx接受请求正在处理，2xx正常处理完毕，3xx需要附加操作,4xx客户端错误，5xx服务器错误.
302临时重定向，401未经许可需要http认证 。503超负荷，无法处理请求。

（最广泛）http1.1相对1.0主要加强缓存处理，宽带优化，错误通知管理，长连接



valatile关键字，解决缓存一致性 总线锁（阻塞其他cpu效率太低）->缓存锁小粒度->MESI(修改、独家、共享、无效)会同步通知其他核失效缓存，性能太低->Store Buffers不用同步等待，写会主存的时候确认就好了。
重排序的原因就是修改了cpu缓存刷新到主存的时间是不确定的，导致后更改的值先刷到主存，在其他线程来看就是乱序了。
内存屏障就是让数据之前的数据对后面的执行都更先刷到主存，对其他线程来说是顺序的。
非常深入的 https://www.toutiao.com/i6859927959499702792/?tt_from=weixin&utm_campaign=client_share&wxshare_count=1&timestamp=1597214361&app=news_article&utm_source=weixin&utm_medium=toutiao_ios&use_new_style=1&req_id=202008121439210100260760220A00FBDC&group_id=6859927959499702792


项目亮点：
tcp半连接,在服务端维护了一个sync的队列，就是半连接队列，从收到请求到第三次握手成established中间会放里面，默认会又50，溢出直接丢掉，客户端在第二次连接之后就established了，所以结果就是客户端认为连接成功，服务端没连接，导致正式传输数据失败。
stock库存高并发优化 : 机器排队，case when sql，日志和扣减的事务的顺序，避免死锁：排序.数据一致性，最终一致性m：上游消息与幂等。
接口测试的维护
设计模式的应用
binlog异步刷缓存

上午算法 经典题目，思想，总结。
    主要算法思想、经典算法
下午1-4,复习基础非算法知识
下午4-6点半，算法总结、常见算法回顾，主要回顾自己做过的和思想，最后复盘只复习，不动题目了

查找大数据前n大的数据，思路是分治法多个文件，然后在对每个文件进行快速排序，二分的大的部分超过n个数就只排序单边就好了

自我介绍：
我叫马培川、
毕业于湖北工业大学信息管理专业，15年在校期间在中国移动实习
毕业后在杭州的个推做过web开发，
17年在阿里的盒马做仓储物流的开发
19年因朋友邀请到现在是格家网络做电商库存的负责人。
业余时间喜欢写点技术博客，也学习日语。
现在由于社交电商业务发展受限希望换一份工作，找个自己喜欢的产品
个人对微视比较感兴趣，// 相比较行业第一更喜欢去行业第二的产品比较有挑战




准备问题：
具体微视哪块业务、杭州团队怎么定位？集群和tps方便透露么？最大的挑战是啥??  

腾讯面试总结，问的问题主要是，在项目中的负责了啥，主要的技术栈，redis的集群高可用，如何做数据持久化，zset的结构，用的什么消息队列，如何做高可用，一个消息可以有多个分区么？mysql的索引数据结构，有没做过SQL优化，mysql如何做主从，如何binlog日志写入，linux常见命令，如何看网络流量的命令。tcp的超时问题，如何防止拥堵，

