## 复习大纲

### jdk数据结构部分
hashMap为什么头插入链表? 设计者觉得后插入被查找的可能性更大。
初始长度16，自动或手动初始化，都是2的幂。
hash值取摸简单，但是效率很低，所以采用位运算。因为2的n次方-1，都是11111..所以都是依赖于输入的哈希值的尾巴，只要哈希函数均匀，就可以均匀。
HashTable在新的代码已经不推荐使用，ConcurrentHashMap更好.HashMap允许一个null为key
HashMap java8增加了红黑树的结构，桶查找算法复杂度O(n)降低到了O(logn) resize的优化。
hashMap线程不安全，put可能造成线程丢失被覆盖，get的时候遇到resize会造成线程不安全, 因为重新resize之后，可能形成循环链表.
HashMap 8之前都是头插入因为作者觉得后写入的值更先访问 wtf，8开始改用尾插法，因为这样能保持扩容后的相对链表的指向方向，避免循环链表
jdk7 使用segment,默认16个，jdk8摈弃了segment。而是node数组，链表超过8会转换为红黑树。
synchronizedMap
fail-safe(拷贝对象遍历) 与  fail-fast区别
hashtable的key不允许为null，因为早期觉得元素都要实现equals和hashCode方法，null肯定没有，但是hashMap会放到一个特殊的位置
ConcurrentHashMap put的时候会CAS尝试写入，失败就自旋，数量大会转换红黑树, 
红黑树的自平衡性比较好，让它高度很低
hashmap负载因子为什么是0.75
ConcurrentHashMap 1.7的segement需要两次hash, 优点就是降低了锁粒度
ConcurrentHashMap 1.8和HashMap基本一致了，不过采用了volatile和CAS来put, 长度大于某个值红黑树结构

treeSet的内部就是treeMap实现，使用的红黑树来实现的.要求key能排序.
冒泡排序就是两两连续比较
选择排序，遍历一遍找到最小，第二遍找第二小...以此类推
插入排序，拿第一个放到开头，第n个元素依次来找已经排序好的数组进行选择位置插入.
希尔排序，是分成若干个数组进行插入排序。

treeMap底层实现的红黑树
AVL树是带了平衡的二叉搜索树

二叉搜索树，在极端情况会退化成链表，查询性能差，所以引入了平衡树，但是平衡树在修改的时候很容易就被破坏结构，所以引入了红黑树，这样改变也能保证logn的复杂度。

### zookeeper 分布式协调技术
zookeeper,znode的数据存储信息,zk适合读多写少，每个节点最大不能1M.
zk集群，更新leader，再更新follower，读取可以任何机器.
一致性采用了ZAB(zk automic broadcast)协议.类似于paxos和raft
zk节点类型，临时节点，临时顺序节点，永久节点，永久顺序节点
zab定义的节点三个状态：looking,  following, leading, observing
选举节点：选举、发现、同步
zxid包含最大事务编号和epoch。
zab : discover->sync->broadcast
顺序一致性：https://segmentfault.com/a/1190000022248118
zk 并不适合做注册中心，会有不一致性的短暂时间负载不够均衡，而且不同机房分区后不能调同机房的机器不合理。
leader挂了，整个集群对外的服务停止开始选举。
3.4 后保留fastLeaderElection，分两个情况，启动集群已经有leader直接同步即可， 没leader就开始zxid和sid的投票信息进行交换，第一轮是投自己然后进行对比，如果收到比自己的大，那第二轮就拿大的继续投票，直到选出leader，由looking变更为following状态,投票的报文里还有队列或则第几轮和状态的标志，避免消息紊乱。 为了避免重复连接tcp，都是sid大的连接sid小的，建立连接就会判断这个sid如果比自己大直接断开 。
zk的不可用体现在可能丢掉部分请求，在选举期间，不提供服务。
脑裂问题是两个集群被分区了，因为有过半机制，所以分区的后，小的分区不会选出leader因为所有机器达成一致也不可能过半。(总机器数量为配置的，所以是直到集群的总量的)
client写请求 -> server1 (如果不是leader就转发给leader) -> leader写入并广播其他follower -> 一半能够ack -> 返回给server1 -> client 成功


### dubbo 框架
调用过程，首先根据机房进行路由，然后在一个子集群里找到一个机器调用(负载均衡)，然后还用集群容错机制.
集群容错：失败自动切换其他机器(默认, 默认重试2次)、快速失败失败即报错、忽略、自动重试、并发调用一个
负载均衡存在4种机制，1.随机机制（默认策略） 2.轮训机制 3.最少活跃调用 4.一致性哈希，相同参数落在一台机器。
dubbo的服务调用者和服务提供者之间是长连接，但是是NIO的模式，多个请求并发共享一个连接,selector读取channel,其中存在的请求返回顺序问题，可以生成一个id去对应。
dubbo 一共划分了10层，不同的分层不一样。
支持很多种协议，dubbo rmi webservice http memcache redis等等
注册中心支持 zk  multiCast redis simple
NIO netty框架
熔断模式有三种，关闭、开启、半开启。主要解决识别熔断和自动回复的过程，尝试放少量请求并计数，连续多少成功就恢复。
降级为了保护当前系统，可以配置返回默认值



### 高性能缓存组件 redis
redis集群方案有redis cluster类似于节点redirect， redis sharding客户端进行路由、proxy代理。几种分片和扩容方式对比。
redis按存储模式可以分为内存和硬盘，硬盘模式是在内存提供索引，内存模式是不依赖硬盘IO
redis压缩的二进制文件， save和bgsave命令，分别阻塞和不阻塞客户进程.可以通过配置来控制频率刷新写入RDB文件.
10w qps
redis快，内存，数据结构，单线程CPU不是瓶颈 ，多路复用IO，非阻塞。
Sorted set（zsort） 实现是使用的 skiplist表是分层链表，加快查询速度，不用遍历了，写入和删除都是随机层，不用动太多指针
redis String的 SDS一系列对空间的优化
rehash渐进式，在重新hash的过程操作两个表，这样避免一次性耗费大量时间处理.
zset 有序链表 使用skipList 
RDB和AOF的备份方式,AOF又分三种模式，主要是频率的控制 ,RDB更多适合大文件和恢复要更快， AOF适合数据的完整性.
redis 事务ACID的A原子性并不能总是保证，因为其没回滚特性，作者认为客户端的代码没问题就不应该报错。
redis 主从复制保持高可用，slave先sync拉取RDB文件，这个时候主master写到缓冲区不写RDB，RDB拉取完了加载到内存，master再同步缓冲区的命令给slave，后续建立连接进行
redis 主从同步，2.8版本之前都是全量同步，但是只是 redis失去连接或则停止运行恢复没必要全部重新拉取，所以slave会发送psync发送id标志和offset，master确认是之前连过就从offset开始同步，否则还是拉全量。
集群数据分布方式：节点取摸，一致性哈希(可以虚拟节点增加均匀，把一个真实节点拆成多个节点均匀分布到环上)，哈希槽(redis-cluster)。
集群的一些坑：批量操作，事务，限制为一个节点
哨兵是新引入一个进程高可用方案，哨兵也是集群，就是监控master是否存活，自动切换当前slave为master, 独立进程，也会互相监控.如果主机挂了，哨兵主观认为其master下线，等待其他哨兵也认为它下线然后进行投票选举新的master
sentinel也是一个集群，会连接所有master和slave redis节点，如果某台机器下线了，先主观下线，再根据其他sentinel节点的信息汇总，超过阀值就会判定为客观下线，进行投票选择新的。其中很多阀值可以进行配置 。
sentinel 会对master进行cmd连接通信，与其他sentinal节点用pub/sub进程通信。 
redis的淘汰策略，就是在有限内存内，如果继续写入，根据策略进行淘汰kv，否则超出了会与磁盘进行频繁交互影响性能，allkeys-lru算法淘汰，volatile-lru:设置过期时间的淘汰，随机淘汰等策略.
lru是根据最近使用的频率来看，用的很少就淘汰
4.0增加LRU，就是访问的频率
主要是从是否设置过过期时间的 key去淘汰，可以根据最先过期，或则通过访问次数和频率.还有比较暴力的随机淘汰策略。
redis的SDS直接存放了字符串的长度，避免了C语言的遍历计算长度和扩容开销，因为拼接一次之后会有个free长度去缓冲，避免每次拼接都扩容带来开销。缩容不会马上删除。 这就是两个解决方案：空间预分配和惰性空间释放.
redis的事务单线程不会中断所以天然保证隔离性,本质是一个队列把命令放进去一起执行。
redis的watch就是在事务开启之前监听某个key变化，乐观锁机制，如果变化了执行就会返回失败
String、Hash  List Set SortedSet HyperLog  GeoHash  Pub/Sub Redis Module  BloomFilter  RedisSearch Redis-ML
redis setnx可以复杂指令把setnx与expire合成为一个指令，原子操作
scan 可以避免 keys的匹配导致的单线程的阻塞，但是可能存在重复的，在客户端进行去重即可，增量式迭代命令可能存在老数据？
list  做异步队列，rpush生产消息，lpop消费消息，没消息就sleep一下或则可以blpop阻塞。
1次消费多次，用pub/sub...pub/sub有些情况消息会丢失，得使用rocketMQ来保证.
redis实现延迟队列的方式, sortedSet，时间戳score,消息内容zadd,消费者zrangebyscore获取n秒前的数据轮训处理。
AOF方式突然掉电，看sync配置，如果不求性能，就每次都sync，如果追求性能就1s一次，最多丢失1s数据。
RDB原理就是fork和cow,fork一个子进程，然后copy on write写入。
pipline可以多个IO合并为一次。
布隆过滤器的缺点是删除比较困难，可能存在误判。
redis的list采用ziplist或则双向链表来实现
hash采用ziplist和哈希表来实现
set用inset和哈希表
zset使用ziplist与skipList实现
缓存穿透（布隆过滤器），缓存击穿（一个线程拿到锁去家在数据库，另一个线程休眠重试查缓存）、缓存雪崩（过期时间离散一些）
skiplist严格的是上层是下层的1/2个节点，但是这样很容易写入一个数据破坏比例，因此redis底层使用的是每一个节点的写入会随机定义一个层数，这样保证了写入的性能. 如果是平衡树写入还要调整比较复杂 ，skiplist就只需要修改相邻的指针，简单快速.
查找单个值Hash更快，查找范围就需要skipList或则树了，但是skipList更灵活一些，写入性能更好。 
redis的zset是一个有序集合，节点数小于128、或则member小于 64（可配置）使用ziplist压缩列表,否则用跳跃表和哈希表去，查询为O(n)复杂度，修改由于首先要定位所以大于O(n)
zset在哈希和跳跃表两个结构维护，可以很快根据member去查询score,也可以很快遍历，但是他们的节点是一个节点，只是引用指向的同一个内存节省空间。
关于zset的结构这里有比较详细的图解：https://redisbook.readthedocs.io/en/latest/datatype/sorted_set.html
redlock是redis自己实现的一套分布式锁算法，平时我们在用的单机版的分布式锁，机器挂了就不可靠了，而且在主从的时候也可能导致锁丢失，所以redis自己实现，原理就是分别获取集群每个节点的锁（设置一个较短的超时时间，避免阻塞），获取锁的耗时必须小于需要锁定的时间 并且 获取到节点的大于一半的节点的锁 即可认为成功，最后再释放。
分布式锁要求的三个特性：安全性(只有一个客户端获取)、无死锁（持有锁的客户端分区崩溃也可以）、容错（redis大多数节点正常即可）
aof机制每次都是追加命令到aof_buf ，通过参数appendfSync配置同步刷磁盘周期，另外其实这样的文件非常大，可以定期进行AOF重写，但是重写的时候新的命令怎么办呢，可以fork一个子进程搞个重写缓冲区aof_rewrite_buf,重写完了再合并.
redis使用的Reactor单线程模型。

redis与zk分布式锁对比,redis不断的抢锁，性能开销会大些，客户端挂了只能等超时。zk不太适合高并发，客户端挂了锁自动失效。

主从复制过程：1.保存主节点信息 2.主从建立socket连接 3.发送ping 4.权限验证 5. 同步数据集 6. 命令持续复制
repl-disable-tcp-nodelay的用途？    yes为合并多个命令，节省带宽，但是一致性延迟大， no为立即同步，没有延迟.
区分全量复制与部分复制
1. slave主动要求全量复制或则master判断发现只能全量复制
主节点执行bgsave RDB + 一个复制缓冲区记录开始执行的所有写命令
先恢复RDB，然后同步复制缓冲区命令
如果从节点开启AOF，也会触发bgrewriteaof保证AOF最新
RDB的传输非常消耗带宽，从节点清除老数据，载入RDB过程是阻塞无法相应命令，bgrewriteaof也带来额外消耗
2. 偏移量、复制缓冲区、runid
主和从都有一个自己的offset偏移量，但是如果主的偏移量大于这个队列的固定长度，说明被挤压的命令存在丢失，只能全量同步了。所以可以通过repl-backlog-size控制缓冲区大小。
从节点网络隔离后恢复可能主节点机器已经变了，所以从节点也会有个主节点的id，如果id不同也会直接全量同步.
从节点slaveof命令，首先判断是否是第一次同步（全量）然后psync {runid}{offset}
心跳检测主要网络状态，min-slaves,检测命令丢失。
主：从节点状态，offset便宜，心跳延迟
    min-slaves-to-write 心跳检测的从的数量低于这个配置的值，那就拒绝写命令
    min-slaves-max-lag 从服务器延迟大于10s，写命令拒绝
    如果检测到从节点offset丢失，重发丢失的数据。
    
主从延迟比较大，可以优化网络，slave-serve-stale-data 如果yes延迟大也可服务，如果no延迟太大只能执行slaveof等少数命令




### 消息队列 mq rocketMQ 与 Kafka
#### rocketMQ
rocketMQ是开源版本，metaQ notify 和aliware MQ都是以rocketMQ为内核开发出来的产品，metaQ主要是pull,解决顺序消息和海量堆积问题， Notify是推模型，解决事务消息， Aliware MQ则是商业化的版本.
rocketMQ : nameServer, broker, producer, consumer
nameServer和zk的功能差不多，但是更轻量
producer只是向master发送消息，但是consumer可以从master和slave订阅消息 
rocket参考的kafka设计的,都采用了零拷贝技术,在可靠性和事务性上做了优化，性能略降低。
吞吐量在十万级别，kafka达到百万级别
kafka 消息还没到broker就返回成功，rocketMQ会保证发送到再返回，因此kafka可能会丢数据 （刚好broker宕机）
因为只需要一个比较轻量高可用的协调集群，所以没引入zk
零拷贝，就是避免CPU把数据从磁盘读取到内核空间缓存和socket缓存的两次复制，用一些技术让出了CPU资源。
消息重复一般都是让消费者控制的，可以redis判断唯一id控制
rocketMQ在4.5之前master-slave是没有故障自动转移，需要人工介入，4.5之后支持故障切换，因为引入了DLedger记录commitLog，可以用raft选举出新的leader
nameServer检查broker存活是有延迟的，因此如何规避broker的问题，一般就是重试和--
rocketMQ一个区别就是采用全局的一个commitlog来记录producer顺序写入的消息， kafka每个partition都一个顺序写入commitlog，在大量partition或则topics会导致IO剧增性能下降。
消息不丢失，发送，broker存储，消费三个阶段。1.发送主要利用刷盘或则主从的，四个状态，成功、刷盘超时、同步slave超时、slave不可用。2. 存储可以开启刷盘成功再返回，默认是5s.
消息不重复消费，consumer消费定期会提交offset给mq,因此存在部分消息重复的可能，幂等保证。
每20s会来重新进行负载均衡
新上了消费节点，节点会心跳通知broker, broker再通知老的节点去开始rebalance. 默认 AllocateMessageQueueAveragely， 例如三个节点消费5个队列，那就 {1,2} {3,4} {5}
#### kafka
高可用的核心就是冗余副本（partition）
leader是partition的维度
创建topic可以设置复制因子，决定副本的个数
一个topics有多个partition分布在不同的机器上，每个partition有多个副本在不同的机器
kafka的写入写入性能取决于ISR集合中最慢的broker接受消息的性能, 运维可以最好识别出来最慢的broker干掉
这个 ISR怎样才算跟得上，这个可以通过参数配置，可以是落后的消息数量也可以是follower主要fetch（也是配置）的延迟时间
replica.lag.time.max.ms就是落后的数量，但是这样可能在峰值的时候频繁删除ISR和恢复，所以kafka是优化了落后数量判断并且下个fetch时间内没追上，才会移除ISR
每个partition（leader patition）都有个一个ISR(In-Sync Replicas)，维护着跟自己partition同步的副本
leader有两个指针，指向committed和logEndOffset，分别指向已经提交的和还没同步完成的.(https://zhuanlan.zhihu.com/p/56440807)
acks参数在生产者里，有三个选项0,1,all.  0-客户端发送出去就不管了，性能最高但是可靠性最差，1-leader保存还没同步就返回成功，all-必须要同步ISR里的机器成功再返回，性能最差
kafka消费者记录offset
Kafka HW:high waterbark,最小的ISR机器的水位 leo:logEndOffset   hw和leo都是最后一条的下一条
顺序性，parition内是顺序写入的，所以消费也是有序，如果要topic有序，那就partitio的个数设置为1，当然这样就没高可用了
kafka consumer如果超过了partition个数，那多余的机器不会消费到topics,所以这里没法线性扩展.
kafka 的高性能，partition的并行处理能力, 磁盘的顺序写能力，把partition分为多个segment，segment对应一个文件，按文件删除.
生产和消费差不多，Page cache避免写入磁盘的等待，直接消费，但是可能宕机丢失，不过可以用partition冗余解决这个问题。
零拷贝 kafka节点投递给消费者的时候避免了内核态到用户态的复制过程 https://www.jianshu.com/p/835ec2d4c170
批量发送消息，和数据压缩，broker发送搞得时候再解压，整个过程磁盘的数据写入写出都降低了


### 分布式事务
XA 资源协调
TCC try-commit-cancel, 要求允许空回滚和幂等,主要解决异步网络通信失败问题，主要的核心就是重试。
soga : 一阶段提交，要么全成功，要么全失败，也是补偿，一阶段，不会对资源长期加锁，吞吐量相对较高
MQ消息: 发送先把消息投递到消息队列，但是此时消息队列的该消息只是prepare状态，不会给消费者消费，直到等生产者执行成功通知mq说该消息成功，这里有个问题，可能网路不好，一直没通知mq,这个时候mq有个定时任务轮训prepare状态的消息来查接口得到状态，如果消费成功则然后通知下游去消费，不断的重试，最终得到一致。
本地消息表:记录表不断的重试，不支持回滚
ACID : 柔性事务一般会放弃强一致和隔离性

### mysql数据库
mysql innoDB如果没定义primary key，就选择第一个唯一键的索引作为pk。
为什么要用自增主键好，因为顺序插入，数据紧凑不需要挪动数据。非自增的话会为了保证B+树的顺序，所以可能频繁移动造成碎片，不紧凑性能降低。
索引，有序，二分查找快
B+是有序的，叶子节点有指针指向。
哈希是无序的，单key查找不需要遍历树，速度极快，但是不擅长范围查询和排序，联合作引左匹配也不支持。
B+查询的时候引擎会分析查询自动触发自适应查询构建哈希索引。客户端不可控制，隐式的。 
表分区是把单表的物理存储拆分成多个，逻辑上还是一个，分表是按某个业务字段进行分表。分区可以存储更多数据，需要并行查询汇总，删数据更容易。
MVCC 提高了读的并发度
limit 1找到一条就停止，可以是一个优化点
MRR(multi range read) 就是读取了索引一起然后排序再去磁盘上拿数据，避免频繁IO磁盘非顺序读。因为mysql都是一页一页的查询，顺序读后一页的缓存不会丢失导致非顺序读重复读某页，会找到需要数据结束后再失效缓存。
B+主要是避免了B树的遍历排序问题
innoDB 存在缓冲管理，索引和数据全部缓存起来，加快查询速度
innoDB相比MySAM最大特点就是支持事务，损失效率换来的
explain的index是索引全部扫描，ref是更快的查找
联合索引的的b+树都是根据第一个索引字段去构建的 
mysql执行:连接器->查询缓存->分析器->优化器，查询缓存是缓存整张表.除非是静态表缓存价值不大。
意向锁是表锁，与其互斥的也是普通表锁，一个数据要对某行加锁，就要先获取表的意向锁再获取表的行锁。意向锁增加了并发度，表和行锁共存。
乐观锁、悲观锁，共享锁和排他锁都是悲观锁。
mysql大量update的时候，就算走的索引也会升级为表锁，因为行锁的开销大。不走索引的话也是直接表锁.
间隙锁，给不存在的数据区间加锁，避免幻读(因此在写多的场景，尽量避免范围加锁, 和大范围加锁)。如果使用条件记录给不存在的记录加锁，也会间隙锁。
update和delete 索引区分度不高的场景，引发锁表。
innoDB有监控线程主动检测死锁并通知，回滚代价最小的那个事务。
show OPEN TABLES where In_use > 0查看是否锁表.
死锁文章https://juejin.im/post/5b82e0196fb9a019f47d1823
内存三大模块：缓冲池、重做缓存池(Redo Log Buffer)和额外内存池. 
innoDB为了抵抗高并发，抵消CPU与IO的速度差异，引入了缓冲池，读就是先读缓存池读不到再读磁盘然后写入到缓存池，跟缓存一样一样的，写的话也是修改缓存池再去刷盘，降低IO交互。当然如果全表扫描的话会导致缓存池被占满，这个采用了LRU算法淘汰避免。
MySQL都是日志先行，写数据前都会Redo Log,定期CheckPoint将RedoLog刷入磁盘。
写入都是批量写入缓存量达到某个值再刷盘。但是这里如果宕机就没办法RedoLog了，所以要用两次写入，不仅写入内存缓冲池，还要在磁盘共享空间也写个副本，避免丢失。
访问热点的页进行hash自适应，类似于JIT。
重做日志缓冲，写RedoLog然后更改缓冲区，更改的页叫脏页，根据Checkpoint将脏页刷到磁盘。
MySQL日志：错误日志、二进制文件、查询日志、慢查询日志。InnoDB日志：Redo Log和Undo Log
Mysql主从复制，master会在启动后开启一个dump线程写入日志并通知slave, slave会启动IO线程和 SQL线程读取和relay日志.
磁盘寻找一次会寻道，寻点，复制到内存。一次IO加在一页，这个一页的大小跟操作系统的bit有关系，可能是8byte或则4byte,加载一页性能高。
MyISAM不需要支持事务，快速返回count(*), innoDB执行count(*)遍历全表，性能差。
在InnoDB下count(id)遍历全表，拿到id累加，count(1)遍历但是不取值直接+1，因此更快。
InnoDB由于MVVC导致可见性，所以无法像MyISAM一样直接缓存行数。count(*) count(1) 会选择最小的二级索引进行遍历。
缓冲池只针对普通索引写入优化（写缓存再写个 redo log），因为非唯一索引还是要去查磁盘无法避免。
change_buffer可以设置大小，优化写入。
行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。
change_buffer对于普通索引和唯一索引的处理还不太一样，普通索引在更新的时候缓存页存在就更新缓存页，不存在也把操作写入缓存页，下次读取到内存再进行merge，唯一索引的话change_buffer不存在就得去查询出来更新。
非唯一键，写多读少的表适合使用changeBuffer，因为多次写入可以进行合并一次merge（当然在关机的时候也会触发merge）
change_buffer写入缓存区存在与否，缓存区存在就直接更新缓存区k1，不存在就写个k2操作在change_buffer，并且顺序写入redolog磁盘.两次内存操作，一次磁盘操作，如果此时崩溃，因为redolog持久化了，所以可以恢复。
读取的时候的时候k1可以直接缓冲区读出来，k2可以在脏页的进行change_buffer的合并得到正确的结果。这个change_buffer会定期刷到磁盘覆盖脏页面。 
redolog顺序写提升，changeBuffer降低IO次数。 
changeBuffer参考：https://www.jb51.net/article/155737.htm
redolog是解决事务的一致性(写入缓冲)、undolog保证事务的原子性(delete对应insert..)
binlog是数据变更，有三种格式:row、statement、mix
explain 语句, const 返回一个性能高 （system是特殊的const），type比较重要,index就是扫描全部索引，如果extra Using index就是走了索引覆盖， row越少越好，说明扫描的少，extra: Using filesort就是按照非B+树的顺序的字段排序了，可以优化掉。
B树和B+树的区别就是 1.B树的非叶子节点也存放了数据，B+树没有，这样就可以让非叶子节点只做索引，可以加载更多索引在内存进行索引，降低IO次数, 查询效率更稳定，数据都存在叶子节点。 2.B+在叶子节点更方便的进行范围查询，叶子节点之间会有指针，内存存储基本也连续。
mysql update如果不走索引是首先加全表加行锁，再过滤把不符合的行锁释放掉，但是这样的开销是很大的。
DML太久可能是purge阻塞导致，由于大事务导致的undo log太多,由于某些大事务一直要读一些需要删除的数据，一直没提交，导致unpurge无法清理，当unpurge list大于某个值时就会阻塞DML请求。
SHOW ENGINE innoDB status;
SHOW global variables LIKE "%lag%"

### JVM
jvm stack frame存放局部变量，操作栈，动态连接，方法出口等信息，与线程生命周期一致,局部变量表再编译期确定大小，不会改变
方法区(也叫非堆)存放类信息，常量，静态变量，jit后的代码的代码等数据，这块垃圾回收主要是常量池的回收也对类的卸载，回收效果一般不太好，
hotspot当成永久代管理方法区，1.8移除，改成了一个叫元空间的一个东西(也就是说从堆内存移动到了物理内存)，与之前的永久代的区别就是这个元空间是受物理内存的限制，不会再抛出OME了.
java可以利用直接内存，虽然不再jvm规范内，但是可以缓冲区nio去操作，这样避免了jvm内的复制过程，有时候可以明显提升性能。
Java内存模型是一个规范，主要规定了线程件的可见性和共享变量的同步，也就是线程私有变量和主内存的一个交互逻辑规范。
堆，方法区，执行引擎和本地接口是线程共享的，栈和程序计数器是线程私有的。
多线程环境下栈创建过多也可以OME，如果栈太深了也可以StackOutflowError
JMM只保证基本的读取和直接(int a = 1)赋值是原子操作
原子性，可见性，有序性
指令重排序单个线程不会影响，但是多个线程
volatile和synchronize都可以保证原子性，volatile是改了之后直接刷新到主存，synchronize是在释放锁之前把所有的改动写入到主存
jvm内存结构，内存模型，对象模型 区分
jvm就是各个部分的一个规范，内存模型就是多线程之间的共享，对象模型就是具体格式
现在都是分代垃圾收集算法，新生代Minior GC非常频繁，回收快。老年代Major GC,速度慢，频率低。
优先年轻代，大对象和长期存活对象进入老年代，为了计算“长期”，会给每个对象一个年龄计数器。默认15(可以配置)次移动还存在就晋升老年代。
判断对象是否死亡，引用计数法效率高，简单，但是循环引用比较麻烦。主要还是靠可达性分析。
引用类型：强引用 内存不够就抛出OME。  软引用 平时不回收，当内存空间不足就回收。  弱引用  回收线程扫描弱引用就回收（优先级比较低，所以不一定会回收），虚引用。
软引用比其他两个更弱的引用更有价值，主要避免OME
扫描到了被标记而已，还可以执行finalize方法，执行完了再检查一次是否可达，如果不可达才可以真的回收。
常量池也是进行引用查看，没有引用就直接回收了。
对于类的标记，实例都回收、该ClassLoader被回收，Class引用没引用，就可以(不是必然)回收。
算法：标记-清除（效率，碎片），复制算法（解决前一个问题，年轻代），标记-整理（老年代），分代收集
eden : survivor = 默认 8 : 1 : 1
老年代对空间比较敏感，年轻代对时间比较敏感
CMS是老年代比较适合的算法是并发标记清除的意思，第一步是初始标记，并发标记，重新标（并发标记期间产生变化，比并发标记短很多），并发清除。初始标记和重新标记仍然需要STW，采用了分周期隔离，只把需要STW的周期才STW, 并发收集，停顿低。
G1就是把堆分成很多region，其中利用卡表等技术优化避免全堆扫描。可预测停顿。
相同类加载的顺序在不同的环境不一致，可能是不同的环境磁盘的排列顺序问题。
jit 机制？

垃圾收集器：
Serial单线程效率高但是STW体验不好.
ParNew就是Serial的多线程版本（并发执行，效率更高，但是也会STW），
Parallel Scavenge与ParNew类似，但更关注吞吐量。
Serial old为Serial的老年代版本。
Parallel Old为Parallel Scavenge的老年代版本。
CMS为最短暂停顿时间为目标的GC(第一款并发收集，与用户线程同时执行,初始标题，并发标记，重新标记，并发清除四个阶段)优点并发收集，低停顿，但是对CPU资源敏感，无法处理浮动垃圾，会产生空间碎片。
G1 高性能多核大内存的机器，最大限度降低STW, 特点：并行并发，分代收集，空间整合，可预测停顿。不产生碎片。

FullGC就是针对各个代要分配的空间不够的情况全面回收。
Minor GC 为新生代（eden和两个survivor）的回收。Eden区满的时候触发。存活的移动到survivor，from -> to (空的)
如果Minor GC回收发现剩下eden和survivor加起来大于survivor就会提前移动到老年代，这样多了之后老年代FullGC都不够溢出就内存泄漏了。
JVM避免Minor GC扫描全堆，因为新生代可能引用老年代对象，要识别GC roots，就扫描到老年代了，可以采用卡表的技术，把老年代按空间大小分成多个卡片，如果有新生代引用的，就把卡表标记为脏卡，到时候寻找GC roots就可以只扫描脏卡了，不需要进行全堆扫描。

jvm的类加载和连接与初始化都是在运行期间完成的，这种策略会增加编程的灵活性，但是会损失一点点性能。
类的生命周期：加载、验证、准备、解析、初始化、使用、卸载。其中解析可以在初始化之后进行，因为要实现动态绑定。
触发加载的唯一五种方式。1. 遇到new、getstatic、putstatic或invokestatic这四条字节码指令时，如果累没有进行初始化，则要先触发初始化；
    2. 使用java.lang.reflect包中的方法对类进行反射调用的时候；
    3. 初始化类时，若发现其父类还没有初始化，则先触发父类的初始化；
    4. 虚拟机启动的时候，虚拟机会先初始化用户指定的包含main()方法的那个类
    5. 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。

数组 new Object[]不会触发初始化。final 阶段的常量会在编译期就放常量池了，不会触发初始化。
类的初始化是类的各个成员赋初始值的过程。
准备是给static变量分配内存设置初始值(类型初始值)的阶段。final的话会池实话为定义值。
解析就是把符号引用转换成直接引用。
初始化是执行类构造<clinit>(注意区分实例构造器)static部分方法的过程。程序员定义的static代码。
类构造器先执行父类再执行子类，可以没有类构造器


## 操作系统
IO 同步还是异步是针对从内核态拷贝到用户态的过程，阻塞和非阻塞意思是发送了IO请求之后需要等待数据就绪还是不用等待。


LinkedBlockingQueue无界队列可以指定，有写和读两个锁（竞争不那么激烈），复杂度更高扩容内存开销大些，内部链表存储。
ArrayBlockingQueue需要指定长度，读写都是一个锁，竞争激烈一下，内存开销小一些。
DelayQueue可以自定义过期时间的获取优先级的队列。
https://juejin.im/post/5c3ac10351882524bb0b337f
底层都是一个AQS同步器，通过CAS的原子操作更新state去更新获取锁的次数，重入锁就增加1.实现了一个队列进行唤醒。
公平锁是让先挂起的先获取锁，但是非公平锁会唤起所有挂起的线程然后抢，可能存在后挂起的先抢到。
sleep 会在中断后清除中断标记
synchronized本质是要加锁排队的阻塞队列，volatile是没有锁的，因此开销会少，使用的是内存屏障。

CAS中的自旋锁一般要设定次数，否则会带来较大的CPU开销.
自旋锁就是用少的cpu占用避免大的线程阻塞中断切换带来的开销。
synchronized 1.6之前效率低就是因为一直使用重量级锁。

## 多线程部分
synchronized降低获取锁的难度。 
synchronized几种状态，锁只有升级，不会降级，偏向锁(如果是存在竞争会释放并升级锁，会有消耗)就是单个线程进入临界区，轻量级锁（会自旋，如果一直得不到可能消耗cpu）就是多个线程交替进入临界区，重量级锁(不自旋了，直接阻塞)是多个线程同时进入临界区。
无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。也就是CAS（CAS是基于无锁机制实现的）。
偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。
偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。
是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。
shutdown是不接收新的执行任务，正在执行等待执行结束，shutdownNow是拒绝新的任务，并且正在执行的也结束。
ThreadPoolExecutor有个allowCoreThreadTimeOut可以允许核心线程被回收
去阻塞队列拿任务超过设置的时间还没拿到就超时线程被回收
SynchronousQueue是无缓冲的队列，必须要消费一个才能放入一个，有公平和非公平两种模式.LinkedBlockingQueue可缓冲的指定大小的队列，两个独立的锁并发写入和读取性能更高，但是GC会产生node开销会大一些。ArrayListBlockingQueue也是有界队列

多线程用于商品查询组装，并发去查询.
分布式锁退款，取消 

spring的循环依赖解决方案，1. 重新设计依赖关系 2.懒加载 3.setter加载
Spring的构造一个对象是先是实例化依赖的对象再设置属性值。实例化了对象就会放到缓存里面，不会再继续递归去实例化。三级缓存不同成品的bean对象.


nio就是避免了bio的一个连接保持一个服务器的内存消耗。采用不停轮询的方式，具体实现java使用了客户端的buffer 和一个双工的channel和服务端的selector去操作的。selector不停的轮询多个channel把数据发送给客户端的buffer
steam是单向，channel是双向的
同步就是要拿结果，无论是等待或则不断的轮询都是同步。异步就是不用等待，通知我就好了。
阻塞就是数据就绪后，采用的方式是等待还是立即返回。

TCP协议的滑动窗口避免阻塞发生。不用每个包都等待。可以等待一批再等待，这样提高网络吞吐量。
Dubbo的SPI机制，就是有个ExtensionLoader可以根据情况加载接口的不同实现。
CopyOnWriteArrayList的思想就是对于并发容器读写分离，但是写入加锁也会阻塞读，这样不好，所以采取复制一个对象写入完成再把原先引用指向来解决，这个可能存在脏读的风险。


算法：
分治法、贪心法、回溯、动态规划。
分治法把大问题化小，每个问题都是独立的问题。
动态规划，是不断的分解问题，把结果进行合并，与分治法的区别就是非独立的问题，建立在之前的结果之上。 

问题：
循环依赖问题
AQS
redis的优化
引用类型
项目亮点和难题
hashMap死锁
StringBuffer 相比StringBuilder的优势
每日算法 
零拷贝技术
消息队列的高可用，顺序性
kafka的消费者于partition是固定的么
kafka的磁盘处理
分布式事务超时
B+结构
表分区具体怎么操作
日活，量级
treeMap与treeSet区别
各个排序算法
线程池参数
redis事务协调
意向锁
流量控制
mybatis事务
https原理
nio bio io
2pc和3pc
mapreduce介绍下

内存屏障

zk的顺序一致性
redis 集群的proxy高可用和高性能问题
java对象创建过程
对象访问定位有几种
双亲委派
dump文件
嵌入式tomcat
RequestMapping和GetMapping区别

对Mike Cohn的测试金字塔了解多少?
Mock或Stub有什么区别?
什么是OAuth ?
什么是CopyOnWrite 
redis怎么实现分布式锁
redis高并发和高可用
redis数据类型和应用
Dubbo SPI机制
redis和zk分布锁对比
redis集群如何做分片
事务的隔离级别如何控制 

自我介绍要谈项目和角色

Java反射原理
Concurrent包实现


腾讯面试针对性准备：
https的解决什么问题
设计一个UDP
tcp的一些滑动机制
协程和线程的区别
GO的一些机制
KMP

threadLocal内存泄漏

----- 
调研：
加强部分：
链表，树的遍历, 
操作系统与网络, GO相关
熟练掌握HTTP/HTTPS协议，理解TCP/IP协议，并具备linux下的网络服务编程经验。
面经

三次握手：
最开始服务器为LISTEN
发起请求，包含随机生成的seq序列号，syn字段设置为1，表示请求连接。 (syn=1, seq=x) 客户端SENT
由服务端回复客户端包含随机生成seq号，syn设置为1， 产生ack=客户端的syn+1  (syn=1, ack=x+1,seq=y) 服务端RCVD
客户端收到请求后，再次回复(syn=1, ack=y+1, seq=x+1) 客户端与服务端ESTABLISHED

三次握手是基于效率和可靠性去考虑的，如果就两次没有最后一次，那客户端可能不需要连接了服务端还干等浪费资源.

四次挥手：
都是established状态
客户端发起断开，(fin=1, seq=x),  客户端变为fin_wait1, 服务点变为close_wait 
服务端响应：(fin=1, ack=x+1, seq=y)  客户端fin_wait2
服务端处理完成响应: (fin=1,ack=x+1,seq=z)
客户端相应:(fin=1, ack=z+1, seq=h) 客户端等待2MSL，服务端LAST_ACK然后关闭

为什么还要等待2msl，因为避免客户端的ack丢包，导致服务器重复请求断开客户端不能识别。

tcp中几个函数：
tcp网络变成的connect就是一个阻塞函数，就是发起三次握手的建立连接.listen是被动链接函数，告诉内核监听，其中一个backlog作用就是设置队列长度.accept就是从established队列中取已经完成的连接 当队列没有完成连接会阻塞。
tcp的流量控制和拥塞控制，流量控制主要通过一个滑动窗口协议保证，但是这样可能存在死锁的，收到了0，第二次窗口设置为一个>0的如果丢失的话就会双方都等待，解决方案就是发送者定时器主动询问窗口大小。
拥塞控制是做用户网络的、主要用慢开始、快重传、快恢复等算法。流量控制主要用于接受者、主要让发送速度让接受者可以接收.

关于tcp的图文：https://blog.51cto.com/jinlong/2065461

加密：
对称加密，私钥是同一个，性能比较高，但是密钥的管理比较困难。
非对称加密，私钥和公钥成对出现，但是速度比较慢。
https就是http的ssl/tls版本，tls为ssl3.0后的版本。tls与ssl3.0加密算法不同，宏观来看效果一样。
https结合两种方式，非对称加密传递密钥，对称加密传输数据。
https连接会通过两次请求响应连接，第一次是请求服务器，获得证书签名的公钥A。然后客户端验证过了再生成一个随机密钥B，用服务端的公钥A，服务器用私钥C解密获得公钥，然后建立连接开始传输数据。

tcp与udp的区别：
tcp有流量控制、保证传输顺序、面向字节流
udp没流量控制、不保证顺序、面向数据包

UDP可靠性传输：udp+数据包序列号、确认和重传机制、CRC校验完整性.

协程和线程一样共享的堆，私有的栈，协程由程序员在协程里显示调度。协程是单线程内的调度切换，cpu调度的单位是线程。

fork(). vfork(). clone(). exec()都是linux创建新进程，linux内核没有线程结构，只有轻量级进程。PriorityQueue
fork创建子进程独立父进程空间
vfork与父线程共享空间，会阻塞父进程直到子进程执行完。
clone为fork的升级版，更灵活的创建，可以创建父进程的兄弟进程。

linux查看网络状态：ifconfig  thtool ip

tcp滑动窗口就是为了解决大数据量的分批发送问题，就像一个窗口移动，所以叫滑动窗口协议，窗口是在tcp三次握手之后协定，不是固定的，会随机调整，数据分四个部分，已发送并且收到回复，已发送还没收到回复，允许发送但还没发送，不允许发送，窗口可以看成[已发送还没通知，可发送还没发送].滑动窗口的意义保证可靠性和传输效率，稳定性。

tcp包头结构：固定20字节(32位*5行)，包含端口，序号，确认号，窗口等.

http客户端状态码，1xx接受请求正在处理，2xx正常处理完毕，3xx需要附加操作,4xx客户端错误，5xx服务器错误.
302临时重定向，401未经许可需要http认证 。503超负荷，无法处理请求。

（最广泛）http1.1相对1.0主要加强缓存处理，宽带优化，错误通知管理，长连接

- 系统设计
分布式id生成
限流算法
降级算法
压测方法、平台、框架
领域驱动设计
流程引擎实现
tmf与nbf
负载均衡算法
一行记录一个字段可能包含多种，可以用位运算
arthas实现原理
LRU算法手写
zset 可以做延迟,score为时间戳，消费者拉取处理再删除，原子性保证可以用lua

大数据去重：1.布隆过滤器（存在误判），2.可以用bitmap,两个bit就可以判断。 3.hash分组，重复的数字一定在每个文件


- 别人面试经验
concurrentHashMap 的分段锁 ，链表和红黑树解决hash冲突，红黑树的特点
synchronized和reetrankLock原理

雪花算法，时间戳+机器id+序列号.在分布式情况下，全局唯一，单机递增，缺点机器之间时间可能不同步，不能一定做到全局递增。
arthas底层使用ASM, CGLIB底层就是它实现的。JVMTI是底层调试
哈希冲突怎么解决
秒杀优化
threadLocal可能存在内存泄漏，弱引用不能彻底去除另一个强引用，要记得remove
LockSupport park可以唤起指定线程
parallelStream 内部操作线程不安全类存在风险
dubbo多种失败机制,故障转移


valatile关键字，解决缓存一致性 总线锁（阻塞其他cpu效率太低）->缓存缩小粒度->MESI(修改、独家、共享、无效)会同步通知其他核失效缓存，嗅探CAS不断循环，无效导致总线带宽达到峰值， 性能太低->Store Buffers不用同步等待，写回主存的时候确认就好了。
重排序的原因就是修改了cpu缓存刷新到主存的时间是不确定的，导致后更改的值先刷到主存，在其他线程来看就是乱序了。
内存屏障就是让数据之前的数据对后面的执行都更先刷到主存，对其他线程来说是顺序的。保证不被重排序影响。
非常深入的 https://www.toutiao.com/i6859927959499702792/?tt_from=weixin&utm_campaign=client_share&wxshare_count=1&timestamp=1597214361&app=news_article&utm_source=weixin&utm_medium=toutiao_ios&use_new_style=1&req_id=202008121439210100260760220A00FBDC&group_id=6859927959499702792
https://juejin.im/post/6844904149536997384


项目亮点：
tcp半连接,在服务端维护了一个sync的队列，就是半连接队列，从收到请求到第三次握手成established中间会放里面，默认会又50，溢出直接丢掉，因为jit还没触发，导致才部署的机器连接剧增，客户端在第二次连接之后就established了，所以结果就是客户端认为连接成功，服务端没连接，导致正式传输数据失败。
stock库存高并发优化 : 机器排队，case when sql，日志和扣减的事务的顺序，避免死锁：排序.数据一致性，最终一致性：上游消息与幂等。
持有锁时间优化、合并redis刷新、异步化、skuId扣减顺序避免死锁问题。
接口测试的维护
设计模式的应用
binlog异步刷缓存

上午算法 经典题目，思想，总结。
    主要算法思想、经典算法
下午1-4,复习基础非算法知识
下午4-6点半，算法总结、常见算法回顾，主要回顾自己做过的和思想，最后复盘只复习，不动题目了

查找大数据前n大的数据，思路是分治法多个文件，然后在对每个文件进行快速排序，二分的大的部分超过n个数就只排序单边就好了

自我介绍：
我叫马培川、
毕业后在杭州的个推做过web开发，
17年在阿里的盒马做仓储物流的开发
19年因朋友邀请到现在是格家网络做电商库存的负责人。
业余时间喜欢写点技术博客，也学习日语。
现在由于社交电商业务发展受限希望换一份工作，找个自己喜欢的产品
个人对微视比较感兴趣，// 相比较行业第一更喜欢去行业第二的产品比较有挑战




准备问题：
具体微视哪块业务、杭州团队怎么定位？集群和tps方便透露么？最大的挑战是啥??  

腾讯面试总结
在项目中的负责了啥，
主要的技术栈，
redis的集群高可用，
如何做数据持久化，
zset的结构，
用的什么消息队列，
如何做高可用，
一个消息可以有多个分区么？
mysql的索引数据结构，
有没做过SQL优化，
mysql如何做主从，
如何binlog日志写入，
linux常见命令，
如何看网络流量的命令。
tcp的超时问题，如何防止拥堵
分布式id生成（雪花算法）


分表的id生成
Java 零拷贝技术
redis 热数据不均匀, 数据倾斜
netty 零拷贝
redis 同步的时候缓存区写满
负载均衡算法
Dubbo 粘包问题 
类型擦除问题

DMA控制器就是直接内存访问的意思是集成在主板的一块自己的模块不需要cpu参与，一般都是磁盘读取文件到磁盘缓存区(DMA)，然后磁盘复制到内核态(DMA)，在CPU复制到用户态，这样上下文的切换和复制的次数会导致性能的降低。  
实现方式就是用mmap代替read函数，可以让用户态共享内核态的缓冲区
所谓的0拷贝并非无拷贝，只是CPU不参与了，都是由DMA参与，在linux2.1内核，可以支持SG-DMA技术更进一步降低复制过程。
内核缓存区就是磁盘的缓存区，PageCache缓存最近被访问的数据，预读功能。
0拷贝技术也不是万能的，在大文件发送可能存在一定风险，会很快占满缓冲区.
早期 I/O 操作，内存与磁盘的数据传输的工作都是由 CPU 完成的，而此时 CPU 不能执行其他任务，会特别浪费 CPU 资源。
于是，为了解决这一问题，DMA 技术就出现了，每个 I/O 设备都有自己的 DMA 控制器，通过这个 DMA 控制器，CPU 只需要告诉 DMA 控制器，我们要传输什么数据，从哪里来，到哪里去，就可以放心离开了。后续的实际数据传输工作，都会由 DMA 控制器来完成，CPU 不需要参与数据传输的工作。
传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。
为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（sendfile 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。
Kafka 和 Nginx 都有实现零拷贝技术，这将大大提高文件传输的性能。
零拷贝技术是基于 PageCache 的，PageCache 会缓存最近访问的数据，提升了访问缓存数据的性能，同时，为了解决机械硬盘寻址慢的问题，它还协助 I/O 调度算法实现了 IO 合并与预读，这也是顺序读比随机读性能好的原因。这些优势，进一步提升了零拷贝的性能。
需要注意的是，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送。
另外，当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。
在 Nginx 里，可以通过配置，设定一个文件大小阈值，针对大文件使用异步 IO 和直接 IO，而对小文件使用零拷贝。


##  linux 命令
查看磁盘 df du
io: top vmstat  iostat
内存 free 
91 解码方法 转移方程要想清楚
55. 跳跃游戏 所有0都跳过即可
11. 盛最多水的容器 容器双指针移动方向 
142. 环形链表 II 快慢指针相遇后，快追针从头开始，相遇的地方就是入口，这个可以证明。 
148. 排序链表 要求nlogn的复杂度，不能额外空间，就可以用递归+归并的方式解决
16. 最接近的三数之和 可以用双指针解决一层循环
15. 三数之和 也是排序好，再用双指针减少一次循环
剑指 Offer 33. 二叉搜索树的后序遍历序列  题目就是要根据一个数组判断是否是二叉搜索树的后序遍历，找到左右子树递归判断即可，注意要判断左右子树是否都小于和大于哦
863. 二叉树中所有距离为 K 的结点 用一个map去存放parent引用
86. 分隔链表 两个链表构造，然后合并

需要再复习：
287. 寻找重复数 
144. 二叉树的前序遍历 非迭代法比较复杂

字节面试问题：
详细了解项目，
算法题目，判断回文链表
限流方案，
链表要求复杂度。
根据项目中设计场景，
链表反转，k个一组
如何设计流量回放不影响线上回放，
skiplist写入选择指针问题，
如何O(1)复杂度找到第n个数字，
如何设计一个站内消息，
延迟队列来限流. 

滴滴：
写代码，观察者模式，
前K大的数字，
有向图的是否存在环。
CAP之中 zk 保证了什么, 什么情况不可用
高并发扣库存优化
如何做限流

2PC和3PC，3PC多一步确认是否能提交事物，降低了锁持有的时间。
rocketMQ，可以有多个leader/master，每个master有slave,默认slave只做高可用，在延迟比较大的情况可以让slave消费
rocketMQ同步和异步刷盘保证高可用，
分布式锁的原子性

雪花算法、redlock
key

压测、限流、java文件转换为字节码.

限流方案：技术的方案方案，但是存在请求峰值的问题，可以用令牌桶（入的速度一定）和漏斗（出的速度一定）的方式，也可以用单机并发来限流。
1.漏斗算法，可以用一个线程池固定的速率来处理，多余的请求可以拒绝策略，2.令牌桶是起一个Timmer定时向桶里添加  参考RateLimiter，3. 时间窗口，4. 并发限流AOP, 可能窗口边界分布不均匀峰值。分布式的话可能用redis和sentinel.


滴滴面试：
如何进行压测
java文件到class文件的详细过程
如何设计限流，如何时间分布不均匀避免峰值
如何进行服务降级
如何解决高并发扣减库存
还有如何做压测的数据模拟
限流框架和降级的框架实现
领域驱动的理解
流程引擎实现细节


腾讯复盘：
1. 如何保证rocketMQ消息不丢失, 不重复消费, producer的唯一标志
2. 商品库存的设计模型
3. redis音频文件缓存

站在前人的肩上





快手一面：
介绍项目
限流算法、与熔断、降级区别
java锁机制，各种锁的区别
AQS实现原理
volatile 实现原理
分布式锁使用、redlock算法
写一个算法题：LC 31.

快手二面：
arthas实现
binlog同步实现
cms与G1的区别
mysql锁实现原理
hsf如何解决包冲突

字节一面：
介绍项目，业务和技术，项目中的难点，如何去解决
springboot集成包冲突怎么解决
JVM不同分区的算法区别
手写算法题：柱子节水问题

字节二面：
自我介绍
项目问题
缓存一致性
RPC设计
zk选举
脑裂问题
如何解决高并发
阿里项目介绍
算法题、最长子串 

字节三面：
自我介绍
介绍你觉得好的项目
如何做负载均衡
服务发现
一致性哈希
zk算法和高可用
mysql的锁类型
分布式事务解决，TCC实现、消耗资源
隔离级别，mvcc，串行化如何实现
短链接服务设计
DDL 小表比较慢的原因
算法题 LC 55、堆排序


三面准备：
设计一个短链接服务
最近怎么学习新技术，在学什么技术：学mysql的日志文件和changeBuffer的设计，并希望能应用在库存的写入上
之前也学习设计模式之类的，当初做表切换就用代理模式去封装双写，让上层不用修改.
自己的职业规划：
三个方面、技术上、软实力、社区 
技术上钻研一块成为专家，主要是mysql和高性能架构
3年内，技术上更加精进，独立负责核心的一块产品，学习资源分配和项目管理相关的，因此我在这边经常作为PM去主导项目，例如...达到比较好的上线节奏。
提升自己社区的影响力，回馈社区。


字节跳动（抖音）面试第一轮：
自我介绍
介绍最熟悉的项目
TCC 二阶段 三阶段 和 本地消息表 分布式事务区别
fastjson 反序列化 必须要求空构造函数问题怎么解决
Mysql的聚集和非聚集索引区别
B+树为什么要最左匹配
扣减库存接口设计 SQL编写
如何实例化一个类
多线程使用场景
jdk8新功能
如何设计本地缓存, null值需要缓存吗
forkjoin用的什么线程池
parallelStream底层线程池是什么
completeService的用途
函数编程接口哪几个
设计一个即时通讯系统
股票卖出算法题 (简单难度)


二面：
介绍项目
写个题目 判断是否有环
智力题  老虎吃羊
为什么char比string更适合存储密码
redis主从复制过程
设计一个微博，要求支持高并发
tcp阻塞控制方案
为什么long类型是8个字节
什么是序列化


0拷贝技术
https://blog.csdn.net/qq_34827674/article/details/108756999?spm=1000.2115.3001.4128
磁盘 IO 是性能最差的一个部分，有一系列的优化
无DMA过程。cpu的read指令，然后磁盘开始把数据准备到磁盘缓冲区产生cpu中断信号，cpu收到中断然后然后写入到pageCache内核缓冲区，再拷贝到用户缓冲区
DMA就是希望设备和内存数据传输的时候，交给DMA不用CPU了。read方法，IO->磁盘中断，DMA负责把数据从磁盘缓冲区复制到内核缓冲区，CPU再介入冲内核缓冲区拷贝到用户缓冲区，返回调用
mmp技术可以避免拷贝到用户态，sendfile可以避免4次切换，SG-DMA可以避免内核缓冲到socket的拷贝，真正实现CPU的零拷贝都由DMA处理，但是至少还是有两次切换。


## 系统设计题目整理
设计一个评分系统，高并发支持，能够迅速得到排名前百分比和打败的人数。
设计一个微信，可以查阅最近的消息和未读消息。
设计一个站内私信
设计一个短链接服务


weibo
用户可以发微博、关注、私信、点赞、转发，评论，容量能支持10亿级别的用户
需要微博的一张表 weibo (id, user_id, content, create_time)
关注关系 user_ralation (user_id, target_user_id, type, create_time)
点赞 weibo_like (weibo_id, user_id, type)
私信 weibo_message(user_id, target_user_id, message, create_time)
评论 weibo_comment  (weibo_id, user_id, commentary, create_time)
因为单表最大500w的话，10亿用户，如果要精确就算，那还要看日活，和机器的性能与最大峰值等等预估，（后面补充）
先按用户id取摸分64个库, 1024张表, 0-15为第一个分片，16-31为第二个库，这样分片.
绝大部分流量为查询流量，因此需要redis实例，每个库也分一个实例，那就64个redis实例.

使用搜索引擎支持用户观看微博，拿到自己关注的用户列表，在去查询数据

深入学习es和mongo分片等等




