IO 同步还是异步是针对从内核态拷贝到用户态的过程，阻塞和非阻塞意思是发送了IO请求之后需要等待数据就绪还是不用等待。


LinkedBlockingQueue无界队列可以指定，有写和读两个锁（竞争不那么激烈），复杂度更高扩容内存开销大些，内部链表存储。
ArrayBlockingQueue需要指定长度，读写都是一个锁，竞争激烈一下，内存开销小一些。
DelayQueue可以自定义过期时间的获取优先级的队列。
https://juejin.im/post/5c3ac10351882524bb0b337f
底层都是一个AQS同步器，通过CAS的原子操作更新state去更新获取锁的次数，重入锁就增加1.实现了一个队列进行唤醒。
公平锁是让先挂起的先获取锁，但是非公平锁会唤起所有挂起的线程然后抢，可能存在后挂起的先抢到。
sleep 会在中断后清除中断标记
synchronized本质是要加锁排队的阻塞队列，volatile是没有锁的，因此开销会少，使用的是内存屏障。

CAS中的自旋锁一般要设定次数，否则会带来较大的CPU开销.
自旋锁就是用少的cpu占用避免大的线程阻塞中断切换带来的开销。
synchronized 1.6之前效率低就是因为一直使用重量级锁。


三次握手：
最开始服务器为LISTEN
发起请求，包含随机生成的seq序列号，syn字段设置为1，表示请求连接。 (syn=1, seq=x) 客户端SENT
由服务端回复客户端包含随机生成seq号，syn设置为1， 产生ack=客户端的syn+1  (syn=1, ack=x+1,seq=y) 服务端RCVD
客户端收到请求后，再次回复(syn=1, ack=y+1, seq=x+1) 客户端与服务端ESTABLISHED

三次握手是基于效率和可靠性去考虑的，如果就两次没有最后一次，那客户端可能不需要连接了服务端还干等浪费资源.

四次挥手：
都是established状态
客户端发起断开，(fin=1, seq=x),  客户端变为fin_wait1, 服务点变为close_wait 
服务端响应：(fin=1, ack=x+1, seq=y)  客户端fin_wait2
服务端处理完成响应: (fin=1,ack=x+1,seq=z)
客户端相应:(fin=1, ack=z+1, seq=h) 客户端等待2MSL，服务端LAST_ACK然后关闭

为什么还要等待2msl，因为避免客户端的ack丢包，导致服务器重复请求断开客户端不能识别。

tcp中几个函数：
tcp网络变成的connect就是一个阻塞函数，就是发起三次握手的建立连接.listen是被动链接函数，告诉内核监听，其中一个backlog作用就是设置队列长度.accept就是从established队列中取已经完成的连接 当队列没有完成连接会阻塞。
tcp的流量控制和拥塞控制，流量控制主要通过一个滑动窗口协议保证，但是这样可能存在死锁的，收到了0，第二次窗口设置为一个>0的如果丢失的话就会双方都等待，解决方案就是发送者定时器主动询问窗口大小。
拥塞控制是做用户网络的、主要用慢开始、快重传、快恢复等算法。流量控制主要用于接受者、主要让发送速度让接受者可以接收.

关于tcp的图文：https://blog.51cto.com/jinlong/2065461

加密：
对称加密，私钥是同一个，性能比较高，但是密钥的管理比较困难。
非对称加密，私钥和公钥成对出现，但是速度比较慢。
https就是http的ssl/tls版本，tls为ssl3.0后的版本。tls与ssl3.0加密算法不同，宏观来看效果一样。
https结合两种方式，非对称加密传递密钥，对称加密传输数据。
https连接会通过两次请求响应连接，第一次是请求服务器，获得证书签名的公钥A。然后客户端验证过了再生成一个随机密钥B，用服务端的公钥A，服务器用私钥C解密获得公钥，然后建立连接开始传输数据。

tcp与udp的区别：
tcp有流量控制、保证传输顺序、面向字节流
udp没流量控制、不保证顺序、面向数据包

UDP可靠性传输：udp+数据包序列号、确认和重传机制、CRC校验完整性.

协程和线程一样共享的堆，私有的栈，协程由程序员在协程里显示调度。协程是单线程内的调度切换，cpu调度的单位是线程。

fork(). vfork(). clone(). exec()都是linux创建新进程，linux内核没有线程结构，只有轻量级进程。PriorityQueue
fork创建子进程独立父进程空间
vfork与父线程共享空间，会阻塞父进程直到子进程执行完。
clone为fork的升级版，更灵活的创建，可以创建父进程的兄弟进程。

linux查看网络状态：ifconfig  thtool ip

tcp滑动窗口就是为了解决大数据量的分批发送问题，就像一个窗口移动，所以叫滑动窗口协议，窗口是在tcp三次握手之后协定，不是固定的，会随机调整，数据分四个部分，已发送并且收到回复，已发送还没收到回复，允许发送但还没发送，不允许发送，窗口可以看成[已发送还没通知，可发送还没发送].滑动窗口的意义保证可靠性和传输效率，稳定性。

tcp包头结构：固定20字节(32位*5行)，包含端口，序号，确认号，窗口等.

http客户端状态码，1xx接受请求正在处理，2xx正常处理完毕，3xx需要附加操作,4xx客户端错误，5xx服务器错误.
302临时重定向，401未经许可需要http认证 。503超负荷，无法处理请求。

（最广泛）http1.1相对1.0主要加强缓存处理，宽带优化，错误通知管理，长连接


DMA控制器就是直接内存访问的意思是集成在主板的一块自己的模块不需要cpu参与，一般都是磁盘读取文件到磁盘缓存区(DMA)，然后磁盘复制到内核态(DMA)，在CPU复制到用户态，这样上下文的切换和复制的次数会导致性能的降低。  
实现方式就是用mmap代替read函数，可以让用户态共享内核态的缓冲区
所谓的0拷贝并非无拷贝，只是CPU不参与了，都是由DMA参与，在linux2.1内核，可以支持SG-DMA技术更进一步降低复制过程。
内核缓存区就是磁盘的缓存区，PageCache缓存最近被访问的数据，预读功能。
0拷贝技术也不是万能的，在大文件发送可能存在一定风险，会很快占满缓冲区.
早期 I/O 操作，内存与磁盘的数据传输的工作都是由 CPU 完成的，而此时 CPU 不能执行其他任务，会特别浪费 CPU 资源。
于是，为了解决这一问题，DMA 技术就出现了，每个 I/O 设备都有自己的 DMA 控制器，通过这个 DMA 控制器，CPU 只需要告诉 DMA 控制器，我们要传输什么数据，从哪里来，到哪里去，就可以放心离开了。后续的实际数据传输工作，都会由 DMA 控制器来完成，CPU 不需要参与数据传输的工作。
传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。
为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（sendfile 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。
Kafka 和 Nginx 都有实现零拷贝技术，这将大大提高文件传输的性能。
零拷贝技术是基于 PageCache 的，PageCache 会缓存最近访问的数据，提升了访问缓存数据的性能，同时，为了解决机械硬盘寻址慢的问题，它还协助 I/O 调度算法实现了 IO 合并与预读，这也是顺序读比随机读性能好的原因。这些优势，进一步提升了零拷贝的性能。
需要注意的是，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送。
另外，当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。
在 Nginx 里，可以通过配置，设定一个文件大小阈值，针对大文件使用异步 IO 和直接 IO，而对小文件使用零拷贝。


查看磁盘 df du
io: top vmstat  iostat
内存 free 




0拷贝技术
https://blog.csdn.net/qq_34827674/article/details/108756999?spm=1000.2115.3001.4128
磁盘 IO 是性能最差的一个部分，有一系列的优化
无DMA过程。cpu的read指令，然后磁盘开始把数据准备到磁盘缓冲区产生cpu中断信号，cpu收到中断然后然后写入到pageCache内核缓冲区，再拷贝到用户缓冲区
DMA就是希望设备和内存数据传输的时候，交给DMA不用CPU了。read方法，IO->磁盘中断，DMA负责把数据从磁盘缓冲区复制到内核缓冲区，CPU再介入冲内核缓冲区拷贝到用户缓冲区，返回调用
mmp技术可以避免拷贝到用户态，sendfile可以避免4次切换，SG-DMA可以避免内核缓冲到socket的拷贝，真正实现CPU的零拷贝都由DMA处理，但是至少还是有两次切换。



素材下载
值得